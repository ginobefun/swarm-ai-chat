import { NextRequest, NextResponse } from 'next/server'
import { createOpenRouter } from '@openrouter/ai-sdk-provider'
import { streamText } from 'ai'
import { addMessageToSession } from '@/lib/database/sessions-prisma'
import { z } from 'zod'
import { prisma } from '@/lib/database/prisma'
import { OrchestratorGraphBuilder, createInitialState } from '@/lib/orchestrator/graphBuilder'
import {
    saveOrchestratorResult,
    getLatestTurnIndex,
    storeActiveGraph,
    getActiveGraph
} from '@/lib/orchestrator/hooks'
import type { OrchestratorState } from '@/lib/orchestrator/types'

// Types
interface ChatMessage {
    role: 'user' | 'assistant' | 'system'
    content: string
    parts?: Array<{
        type: string
        text: string
    }>
}

// Request validation schema
const ChatRequestSchema = z.object({
    sessionId: z.string().uuid(),
    message: z.string().min(1).optional(), // Optional for AI SDK format
    agentId: z.string().optional(),
    userId: z.string(),
    confirmedIntent: z.string().optional() // For multi-agent clarification
})

/**
 * POST /api/chat
 * Unified chat endpoint that automatically handles:
 * - Single-agent mode: Traditional streaming chat
 * - Multi-agent mode: LangGraph orchestration
 * 
 * The server analyzes the session and decides the processing method
 */
export async function POST(req: NextRequest) {
    try {
        console.log('ğŸ” Unified Chat API - Starting request processing')
        const body = await req.json()
        console.log('ğŸ” Chat API - Received body:', {
            hasMessages: !!body.messages,
            messagesLength: body.messages?.length,
            sessionId: body.sessionId,
            userId: body.userId,
            agentId: body.agentId,
            hasConfirmedIntent: !!body.confirmedIntent
        })

        // Extract message from Vercel AI SDK format (messages array) or direct format
        const messageContent = body.messages?.slice(-1)[0]?.content || body.message
        console.log('ğŸ” Chat API - Extracted message content:', messageContent?.substring(0, 100) + '...')

        // Validate request data
        const { sessionId, agentId = 'gemini-flash', userId, confirmedIntent } = ChatRequestSchema.parse({
            ...body,
            message: messageContent
        })
        console.log('ğŸ” Chat API - Validation passed:', { sessionId, agentId, userId, hasConfirmedIntent: !!confirmedIntent })

        // Validate message content
        if (!messageContent || typeof messageContent !== 'string') {
            throw new Error('Message content is required')
        }

        // ğŸ¯ KEY CHANGE: Analyze session to determine processing mode
        console.log('ğŸ” Analyzing session configuration...')
        const sessionAnalysis = await analyzeSession(sessionId, userId)
        console.log('ğŸ“Š Session analysis result:', sessionAnalysis)

        if (sessionAnalysis.isMultiAgent) {
            // Multi-agent mode: Use LangGraph orchestration
            console.log('ğŸ¤– Using multi-agent orchestration mode')
            return await handleMultiAgentChat(sessionId, messageContent, userId, confirmedIntent, sessionAnalysis)
        } else {
            // Single-agent mode: Use traditional streaming
            console.log('âš¡ Using single-agent streaming mode')
            return await handleSingleAgentChat(body, sessionId, messageContent, userId, agentId)
        }

    } catch (error) {
        console.error('âŒ Unified Chat API Error:', error)

        if (error instanceof z.ZodError) {
            return NextResponse.json(
                {
                    success: false,
                    error: 'Invalid request data',
                    details: error.errors
                },
                { status: 400 }
            )
        }

        return NextResponse.json(
            {
                success: false,
                error: error instanceof Error ? error.message : 'Internal server error'
            },
            { status: 500 }
        )
    }
}

/**
 * Analyze session to determine processing mode
 */
async function analyzeSession(sessionId: string, userId: string) {
    try {
        // First, find the SwarmUser record
        const swarmUser = await prisma.swarmUser.findUnique({
            where: { userId: userId }
        })

        if (!swarmUser) {
            throw new Error('User not found in swarm system')
        }

        // Get session with participants
        const session = await prisma.swarmChatSession.findUnique({
            where: { id: sessionId },
            include: {
                participants: {
                    include: {
                        agent: true
                    }
                }
            }
        })

        if (!session) {
            throw new Error('Session not found')
        }

        // Check authorization
        if (session.createdById !== swarmUser.id) {
            throw new Error('Unauthorized access to session')
        }

        // Analyze agent participants
        const agentParticipants = session.participants.filter(p => p.agentId)
        const agentIds = agentParticipants.map(p => p.agentId!)

        console.log('ğŸ“Š Session analysis:', {
            sessionId,
            totalParticipants: session.participants.length,
            agentParticipants: agentParticipants.length,
            agentIds,
            primaryAgent: session.primaryAgentId
        })

        return {
            isMultiAgent: agentParticipants.length > 1,
            agentIds,
            primaryAgentId: session.primaryAgentId || agentIds[0] || 'gemini-flash',
            session,
            swarmUser
        }
    } catch (error) {
        console.error('âŒ Session analysis failed:', error)
        throw error
    }
}

/**
 * Handle multi-agent orchestration mode
 */
async function handleMultiAgentChat(
    sessionId: string,
    message: string,
    userId: string,
    confirmedIntent?: string,
    sessionAnalysis?: {
        isMultiAgent: boolean
        agentIds: string[]
        primaryAgentId: string
        session: {
            id: string
            participants: Array<{ agentId?: string | null }>
        }
        swarmUser: {
            id: string
            userId: string
        }
    }
) {
    try {
        console.log('ğŸ¬ Starting multi-agent orchestration...')

        // Save user message to database
        console.log('ğŸ’¾ Saving user message to database...')
        await addMessageToSession({
            sessionId,
            senderType: 'user',
            senderId: userId,
            content: message,
            contentType: 'text'
        })

        const agentIds = sessionAnalysis?.agentIds || []

        // Check if there's already an active graph for this session
        let graph = getActiveGraph(sessionId)
        let state: OrchestratorState

        if (graph && confirmedIntent) {
            console.log('ğŸ”„ Continuing existing graph with confirmed intent')
            const turnIndex = await getLatestTurnIndex(sessionId)
            state = createInitialState(sessionId, message, turnIndex)
            state.confirmedIntent = confirmedIntent
            state.shouldClarify = false
        } else {
            console.log('ğŸ†• Creating new orchestrator graph')
            const builder = new OrchestratorGraphBuilder({
                sessionId,
                participants: agentIds
            })

            graph = builder.build()
            storeActiveGraph(sessionId, graph)

            const turnIndex = await getLatestTurnIndex(sessionId) + 1
            state = createInitialState(sessionId, message, turnIndex)
        }

        // Execute graph
        console.log('ğŸ¬ Running orchestrator graph...')
        const startTime = Date.now()
        const finalState = await graph.invoke(state)
        const executionTime = Date.now() - startTime

        console.log('âœ… Graph execution completed:', {
            executionTimeMs: executionTime,
            finalTurnIndex: finalState.turnIndex,
            shouldClarify: finalState.shouldClarify,
            hasSummary: !!finalState.summary,
            tasksCount: finalState.tasks?.length || 0,
            resultsCount: finalState.results?.length || 0,
            eventsCount: finalState.events?.length || 0,
            costUSD: finalState.costUSD
        })

        // Save orchestrator result
        console.log('ğŸ’¾ Saving orchestrator result...')
        await saveOrchestratorResult(finalState)

        // Return orchestrator response as streaming-compatible text
        const response = {
            success: true,
            turnIndex: finalState.turnIndex,
            shouldClarify: finalState.shouldClarify,
            clarificationQuestion: finalState.clarificationQuestion,
            summary: finalState.summary,
            events: finalState.events || [],
            tasks: finalState.tasks || [],
            results: finalState.results || [],
            costUSD: finalState.costUSD || 0
        }

        console.log('ğŸ‰ Multi-agent orchestration completed successfully')

        // Create a streaming response that sends the orchestrator data as valid JSON
        const stream = new ReadableStream({
            start(controller) {
                const encoder = new TextEncoder()

                try {
                    // Send response directly as streaming data (no double JSON encoding)
                    const dataChunk = `data: ${JSON.stringify(response)}\n\n`
                    console.log('ğŸ“¤ Sending orchestrator stream data:', {
                        chunkLength: dataChunk.length,
                        responseKeys: Object.keys(response),
                        preview: dataChunk.substring(0, 100),
                        format: 'direct_json'
                    })

                    controller.enqueue(encoder.encode(dataChunk))
                    controller.enqueue(encoder.encode('data: [DONE]\n\n'))
                    controller.close()
                } catch (streamError) {
                    console.error('ğŸš¨ Stream creation error:', streamError)
                    // Fallback: send minimal response
                    const fallbackData = JSON.stringify({
                        success: true,
                        message: 'Orchestration completed',
                        turnIndex: finalState.turnIndex
                    })
                    controller.enqueue(encoder.encode(`data: ${fallbackData}\n\n`))
                    controller.enqueue(encoder.encode('data: [DONE]\n\n'))
                    controller.close()
                }
            }
        })

        return new Response(stream, {
            headers: {
                'Content-Type': 'text/plain; charset=utf-8',
                'Transfer-Encoding': 'chunked'
            }
        })

    } catch (error) {
        console.error('âŒ Multi-agent orchestration failed:', error)
        throw error
    }
}

/**
 * Handle single-agent streaming mode
 */
async function handleSingleAgentChat(
    body: { messages?: ChatMessage[] },
    sessionId: string,
    messageContent: string,
    userId: string,
    agentId: string
) {
    try {
        console.log('âš¡ Starting single-agent streaming...')

        // Save user message to database
        console.log('ğŸ’¾ Saving user message to database...')
        await addMessageToSession({
            sessionId,
            senderType: 'user',
            senderId: userId,
            content: messageContent,
            contentType: 'text'
        })

        // Get all messages for context
        const allMessages = body.messages || []

        // Create OpenRouter provider
        if (!process.env.OPENROUTER_API_KEY) {
            throw new Error('OPENROUTER_API_KEY is not configured')
        }

        const openrouter = createOpenRouter({
            apiKey: process.env.OPENROUTER_API_KEY,
            headers: {
                'HTTP-Referer': process.env.BETTER_AUTH_URL || 'http://localhost:3000',
                'X-Title': 'SwarmAI.chat'
            }
        })

        const modelName = getModelForAgent(agentId)
        const model = openrouter.chat(modelName)
        const systemPrompt = getAgentSystemPrompt(agentId)

        const startTime = Date.now()

        // Prepare messages for AI model
        const aiMessages = [
            { role: 'system' as const, content: systemPrompt },
            ...allMessages.map((msg: ChatMessage) => ({
                role: msg.role,
                content: msg.content
            }))
        ]

        // Stream AI response
        const result = await streamText({
            model,
            messages: aiMessages,
            temperature: 0.7,
            maxTokens: 2048,
            onFinish: async (completion) => {
                try {
                    const processingTime = Date.now() - startTime
                    const tokenCount = completion.usage?.totalTokens || 0
                    const cost = calculateCost(tokenCount, modelName)

                    await addMessageToSession({
                        sessionId,
                        senderType: 'agent',
                        senderId: agentId,
                        content: completion.text,
                        contentType: 'text',
                        tokenCount,
                        processingTime,
                        cost
                    })

                    console.log(`âœ… Single-agent response saved:`, {
                        agentId,
                        tokenCount,
                        processingTime: `${processingTime}ms`,
                        cost: `$${cost.toFixed(4)}`
                    })
                } catch (error) {
                    console.error('âŒ Error saving single-agent response:', error)
                }
            }
        })

        console.log('âœ… Single-agent streaming response created')
        return result.toDataStreamResponse()

    } catch (error) {
        console.error('âŒ Single-agent streaming failed:', error)
        throw error
    }
}

/**
 * Get OpenRouter model name based on agent ID
 */
function getModelForAgent(agentId: string): string {
    const agentModels: Record<string, string> = {
        'gemini-flash': 'google/gemini-2.0-flash-exp:free',
        'general-assistant': 'google/gemini-2.0-flash-exp:free',
        'article-summarizer': 'google/gemini-2.0-flash-exp:free',
        'critical-thinker': 'anthropic/claude-3.5-sonnet',
        'creative-writer': 'anthropic/claude-3.5-sonnet',
        'code-expert': 'anthropic/claude-3.5-sonnet',
        'data-scientist': 'anthropic/claude-3.5-sonnet',
        'education-tutor': 'google/gemini-2.0-flash-exp:free',
        'researcher': 'anthropic/claude-3.5-sonnet'
    }

    return agentModels[agentId] || 'google/gemini-2.0-flash-exp:free'
}

/**
 * Get system prompt based on agent ID
 */
function getAgentSystemPrompt(agentId: string): string {
    const agentPrompts: Record<string, string> = {
        'gemini-flash': `ä½ æ˜¯ Gemini Flashï¼Œä¸€ä¸ªå¿«é€Ÿé«˜æ•ˆçš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´ã€å‡†ç¡®çš„æ–¹å¼å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`,
        'general-assistant': `ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£å†³å„ç§é—®é¢˜ã€‚è¯·ä¿æŒå‹å¥½ã€æœ‰å¸®åŠ©çš„æ€åº¦ã€‚`,
        'article-summarizer': `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ç« æ‘˜è¦å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. å¿«é€Ÿç†è§£æ–‡ç« çš„æ ¸å¿ƒå†…å®¹
2. æå–å…³é”®ä¿¡æ¯å’Œè¦ç‚¹
3. ç”Ÿæˆç®€æ´å‡†ç¡®çš„æ‘˜è¦
4. ä¿æŒåŸæ–‡çš„è¯­è°ƒå’Œé£æ ¼`,
        'critical-thinker': `ä½ æ˜¯ä¸€ä¸ªæ‰¹åˆ¤æ€§æ€è€ƒä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ†æé—®é¢˜çš„å¤šä¸ªè§’åº¦
2. è¯†åˆ«æ½œåœ¨çš„é€»è¾‘æ¼æ´
3. æå‡ºæ·±å±‚æ¬¡çš„é—®é¢˜
4. æä¾›å¹³è¡¡å’Œå®¢è§‚çš„è§‚ç‚¹`,
        'creative-writer': `ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ›ä½œå¯Œæœ‰æƒ³è±¡åŠ›çš„å†…å®¹
2. è¿ç”¨ç”ŸåŠ¨çš„è¯­è¨€å’Œæ¯”å–»
3. æ„å»ºå¼•äººå…¥èƒœçš„æ•…äº‹æƒ…èŠ‚
4. ä¿æŒåˆ›æ–°å’ŒåŸåˆ›æ€§`,
        'code-expert': `ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. æä¾›é«˜è´¨é‡çš„ä»£ç è§£å†³æ–¹æ¡ˆ
2. è§£é‡Šç¼–ç¨‹æ¦‚å¿µå’Œæœ€ä½³å®è·µ
3. è°ƒè¯•å’Œä¼˜åŒ–ä»£ç 
4. æ¨èåˆé€‚çš„æŠ€æœ¯æ ˆå’Œå·¥å…·`,
        'data-scientist': `ä½ æ˜¯ä¸€ä¸ªæ•°æ®ç§‘å­¦ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ†æå’Œè§£è¯»æ•°æ®
2. æä¾›ç»Ÿè®¡æ´å¯Ÿ
3. å»ºè®®æ•°æ®å¤„ç†æ–¹æ³•
4. è§£é‡Šæœºå™¨å­¦ä¹ æ¦‚å¿µ`,
        'education-tutor': `ä½ æ˜¯ä¸€ä¸ªæ•™è‚²å¯¼å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»¥æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå¤æ‚æ¦‚å¿µ
2. æä¾›å­¦ä¹ å»ºè®®å’Œèµ„æº
3. é¼“åŠ±å­¦ç”Ÿçš„å­¦ä¹ è¿›ç¨‹
4. é€‚åº”ä¸åŒçš„å­¦ä¹ é£æ ¼`,
        'researcher': `ä½ æ˜¯ä¸€ä¸ªç ”ç©¶ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. è¿›è¡Œæ·±å…¥çš„ä¿¡æ¯æœé›†
2. åˆ†æèµ„æ–™çš„å¯é æ€§
3. æä¾›ç»¼åˆæ€§çš„ç ”ç©¶æŠ¥å‘Š
4. æå‡ºè¿›ä¸€æ­¥ç ”ç©¶çš„æ–¹å‘`
    }

    return agentPrompts[agentId] || agentPrompts['general-assistant']
}

/**
 * Calculate cost based on token usage and model
 * OpenRouter pricing varies by model
 */
function calculateCost(tokenCount: number, modelName: string): number {
    // Cost per 1K tokens for different models (in USD)
    const modelCosts: Record<string, number> = {
        'google/gemini-2.0-flash-exp:free': 0, // Free model
        'anthropic/claude-3.5-sonnet': 0.003,
        'openai/gpt-4o': 0.005
    }

    const costPer1K = modelCosts[modelName] || 0.001
    return (tokenCount / 1000) * costPer1K
}